lasso.mod <- glmnet(x = model.matrix(Apps ~ ., College.train)[,-2],
y = College.train$Apps,
alpha = 1,
lambda = lasso.bestlam)
lasso.pred <- predict(lasso.mod,
s = lasso.bestlam,
newx = model.matrix(Apps ~ ., College.test)[,-2])
mean((lasso.pred - College.test$Apps)^2)
lasso.mod.full <- glmnet(x = model.matrix(Apps ~ ., College)[,-2],
y = College$Apps,
alpha = 1,
lambda = lasso.bestlam)
lasso.coef <- predict(lasso.mod.full,
type="coefficients",
s=lasso.bestlam)[1:18,]
lasso.coef <- lasso.coef[lasso.coef!=0]
lasso.coef
# (e)
set.seed(1)
pcr.fit <- pcr(Apps ~ .,
data = College.train,
scale = TRUE,
validation = "CV")
validationplot(pcr.fit,
val.type = "MSEP")
pcr.pred <- predict(pcr.fit,
model.matrix(Apps ~ ., College.test)[,-2],
ncomp = 16)
mean((pcr.pred - College.test$Apps)^2)
pcr.fit.full <- pcr(Apps ~ .,
data = College,
scale = TRUE,
ncomp = 16)
summary(pcr.fit.full)
# (f)
set.seed(1)
plsr.fit <- plsr(Apps ~ .,
data = College.train,
scale = TRUE,
validation = "CV")
validationplot(plsr.fit,
val.type = "MSEP")
plsr.pred <- predict(plsr.fit,
model.matrix(Apps ~ ., College.test)[,-2],
ncomp = 10)
mean((plsr.pred - College.test$Apps)^2)
plsr.fit.full <- pcr(Apps ~ .,
data = College,
scale = TRUE,
ncomp = 10)
summary(plsr.fit)
detach(College)
# 2
data(Boston)
attach(Boston)
# (a)
set.seed(1)
train=sample(c(TRUE,FALSE), nrow(Boston),rep=TRUE)
train.Boston <- Boston[train, ]
test.Boston <- Boston[!train, ]
# (b)
lm.fit_2 <- lm(crim ~ .,
data = train.Boston)
lm.pred_2 <- predict(object = lm.fit_2,
newdata = subset(test.Boston, select = -crim))
mean((lm.pred_2 - test.Boston$crim)^2)
# (c)
predict.regsubsets <- function(object,newdata,id,...){
form <- as.formula(object$call[[2]])
mat <- model.matrix(form,newdata)
coefi <- coef(object, id = id)
xvars <- names(coefi)
mat[, xvars]%*%coefi
}
k <- 10    #set number of fold
set.seed(1)
folds=sample(1:k,
nrow(train.Boston),
replace = TRUE)
cv.errors <- matrix(NA,
k,
13,
dimnames=list(NULL, paste(1:13)))
for(j in 1:k){
best.fit <- regsubsets(crim ~ .,
data=train.Boston[folds != j, ],
nvmax=13)
for(i in 1:13){
pred <- predict(best.fit,
train.Boston[folds == j, ],
id = i)
cv.errors[j,i] <- mean( ( train.Boston$crim[folds == j] - pred )^2 )
}
}
mean.cv.errors <- apply(cv.errors, 2, mean)
best.ind <- which.min(mean.cv.errors)
reg.best=regsubsets(crim ~ . ,
data=train.Boston,
nvmax=13)
list("Number of Variables" = length(coef(reg.best, best.ind)),
"Name of Variables" = attr(coef(reg.best, best.ind), "names"),
"Coefficients of Variables" = coef(reg.best, best.ind),
"MSE" = min(mean.cv.errors))
# (d).
set.seed(1)
ridge.cv.out <- cv.glmnet(x = model.matrix(crim ~ ., train.Boston)[,-1],
y = train.Boston$crim,
alpha = 0)
ridge.bestlam <- ridge.cv.out$lambda.min
ridge.mod <- glmnet(x = model.matrix(crim ~ ., train.Boston)[,-1],
y = train.Boston$crim,
alpha = 0,
lambda = ridge.bestlam)
ridge.pred <- predict(ridge.mod,
s = ridge.bestlam,
newx = model.matrix(crim ~ ., test.Boston)[,-1])
list("Lambda" = ridge.bestlam,
"MSE" = mean((ridge.pred - test.Boston$crim)^2))
# (e).
set.seed(1)
lasso.cv.out <- cv.glmnet(x = model.matrix(crim ~ ., train.Boston)[,-1],
y = train.Boston$crim,
alpha = 1)
lasso.bestlam <- lasso.cv.out$lambda.min
lasso.mod <- glmnet(x = model.matrix(crim ~ ., train.Boston)[,-1],
y = train.Boston$crim,
alpha = 1,
lambda = lasso.bestlam)
lasso.pred <- predict(lasso.mod,
s = lasso.bestlam,
newx = model.matrix(crim ~ ., test.Boston)[,-1])
lasso.coef <- predict(lasso.mod,
type = "coefficients",
s = lasso.bestlam)[1:14,]
list("Lambda" = lasso.bestlam,
"MSE" = mean((lasso.pred - test.Boston$crim)^2),
"Non-zero Coefficient Estimates" = lasso.coef[lasso.coef != 0],
"Name of Variables with Zero Coefficient Estimates" =
names(lasso.coef)[which(lasso.coef == 0)])
# (f).
set.seed(1)
pcr.fit <- pcr(crim ~ .,
data = train.Boston,
scale = TRUE,
validation = "CV")
validationplot(pcr.fit,
val.type = "MSEP")
M.ind <- which.min(RMSEP(pcr.fit)$val[1, 1, ])
best.pcr.fit <- attr(RMSEP(pcr.fit)$val, "dimnames")$model[M.ind]
M <- as.numeric(gsub("([0-9]+).*$", "\\1", best.pcr.fit))
pcr.pred <- predict(pcr.fit,
model.matrix(crim ~ ., test.Boston)[,-1],
ncomp = M)
mean((pcr.pred - test.Boston$crim)^2)
# (g)
set.seed(1)
plsr.fit <- plsr(crim ~ .,
data = train.Boston,
scale = TRUE,
validation = "CV")
validationplot(plsr.fit,
val.type = "MSEP")
M.ind <- which.min(RMSEP(plsr.fit)$val[1, 1, ])
best.plsr.fit <- attr(RMSEP(plsr.fit)$val, "dimnames")$model[M.ind]
M <- as.numeric(gsub("([0-9]+).*$", "\\1", best.plsr.fit))
plsr.pred <- predict(plsr.fit,
model.matrix(crim ~ ., test.Boston)[,-1],
ncomp = M)
mean((plsr.pred - test.Boston$crim)^2)
# 3
if (!file.exists("./forestfires.csv"))
download.file(url = "http://www.dsi.uminho.pt/~pcortez/forestfires/forestfires.csv",
destfile = "./forestfires.csv")
forestfires <- read.csv(file = "./forestfires.csv",
header = TRUE)
Data <- subset(mutate(forestfires, log_area = log(area + 1)),
select = -area)
N <- 12 - 2 + (12 - 1) + (7 - 1)
set.seed(1)
train=sample(c(TRUE,FALSE), nrow(Data),rep=TRUE)
train.Data <- Data[train, ]
test.Data <- Data[!train, ]
# (d).
set.seed(1)
ridge.cv.out <- cv.glmnet(x = model.matrix(log_area ~ ., train.Data)[,-1],
y = train.Data$log_area,
alpha = 0)
ridge.bestlam <- ridge.cv.out$lambda.min
ridge.mod <- glmnet(x = model.matrix(log_area ~ ., train.Data)[,-1],
y = train.Data$log_area,
alpha = 0,
lambda = ridge.bestlam)
ridge.pred <- predict(ridge.mod,
s = ridge.bestlam,
newx = model.matrix(log_area ~ ., test.Data)[,-1])
list("Lambda" = ridge.bestlam,
"MSE" = mean((ridge.pred - test.Data$log_area)^2))
# (e).
set.seed(1)
lasso.cv.out <- cv.glmnet(x = model.matrix(log_area ~ ., train.Data)[,-1],
y = train.Data$log_area,
alpha = 1)
lasso.bestlam <- lasso.cv.out$lambda.min
lasso.mod <- glmnet(x = model.matrix(log_area ~ ., train.Data)[,-1],
y = train.Data$log_area,
alpha = 1,
lambda = lasso.bestlam)
lasso.pred <- predict(lasso.mod,
s = lasso.bestlam,
newx = model.matrix(log_area ~ ., test.Data)[,-1])
lasso.coef <- predict(lasso.mod,
type = "coefficients",
s = lasso.bestlam)[1:14,]
list("Lambda" = lasso.bestlam,
"MSE" = mean((lasso.pred - test.Data$log_area)^2),
"Non-zero Coefficient Estimates" = lasso.coef[lasso.coef != 0],
"Name of Variables with Zero Coefficient Estimates" =
names(lasso.coef)[which(lasso.coef == 0)])
# (f).
set.seed(1)
pcr.fit <- pcr(log_area ~ .,
data = train.Data,
scale = FALSE,
validation = "CV")
validationplot(pcr.fit,
val.type = "MSEP")
M.ind <- which.min(RMSEP(pcr.fit)$val[1, 1, ])
best.pcr.fit <- attr(RMSEP(pcr.fit)$val, "dimnames")$model[M.ind]
M <- as.numeric(gsub("([0-9]+).*$", "\\1", best.pcr.fit))
pcr.pred <- predict(pcr.fit,
model.matrix(log_area ~ ., test.Data)[, -1],
ncomp = M)
mean((pcr.pred - test.Data$log_area)^2)
# (g)
set.seed(1)
plsr.fit <- plsr(log_area ~ .,
data = train.Data,
scale = TRUE,
validation = "CV")
validationplot(plsr.fit,
val.type = "MSEP")
M.ind <- which.min(RMSEP(plsr.fit)$val[1, 1, ])
best.plsr.fit <- attr(RMSEP(plsr.fit)$val, "dimnames")$model[M.ind]
M <- as.numeric(gsub("([0-9]+).*$", "\\1", best.plsr.fit))
plsr.pred <- predict(plsr.fit,
model.matrix(log_area ~ ., test.Data[,-1],
ncomp = M))
mean((plsr.pred - test.Data$log_area)^2)
attr(coef(reg.best, best.ind), "names")
attr(coef(reg.best, best.ind), "names")[-1]
paste(attr(coef(reg.best, best.ind), "names")[-1],collapse = " + ")
predict.lm
?predict.lm
reg.best=regsubsets(crim ~ . ,
data=train.Boston,
nvmax=13)
best.lm <- lm(as.formula(paste("crim ~ ",
paste(attr(coef(reg.best, best.ind),
"names")[-1],
collapse = " + "))),
data = train.Boston)
best.predict <- predict(best.lm,
newdata = train.Boston)
list("Number of Variables" = length(coef(reg.best, best.ind)),
"Name of Variables" = attr(coef(reg.best, best.ind), "names"),
"Coefficients of Variables" = coef(reg.best, best.ind),
"MSE" = mean((best.pred - test.Boston$crim)^2)
)
best.pred
best.lm
best.predict <- predict(best.lm,
newdata = test.Boston)
best.predict
list("Number of Variables" = length(coef(reg.best, best.ind)),
"Name of Variables" = attr(coef(reg.best, best.ind), "names"),
"Coefficients of Variables" = coef(reg.best, best.ind),
"MSE" = mean((best.pred - test.Boston$crim)^2))
best.lm <- lm(as.formula(paste("crim ~ ",
paste(attr(coef(reg.best, best.ind),
"names")[-1],
collapse = " + "))),
data = train.Boston)
best.predict <- predict(best.lm,
newdata = test.Boston)
list("Number of Variables" = length(coef(reg.best, best.ind)),
"Name of Variables" = attr(coef(reg.best, best.ind), "names"),
"Coefficients of Variables" = coef(reg.best, best.ind),
"MSE" = mean((best.pred - test.Boston$crim)^2))
best.lm <- lm(as.formula(paste("crim ~ ",
paste(attr(coef(reg.best, best.ind),
"names")[-1],
collapse = " + "))),
data = train.Boston)
best.pred <- predict(best.lm,
newdata = test.Boston)
list("Number of Variables" = length(coef(reg.best, best.ind)),
"Name of Variables" = attr(coef(reg.best, best.ind), "names"),
"Coefficients of Variables" = coef(reg.best, best.ind),
"MSE" = mean((best.pred - test.Boston$crim)^2))
cor(Data)
cor(Data[, c(-3, -4)])
as.numeric(Data)
sapply(Data, as.numeric)
cor(Data)
str(Data)
cor(sapply(Data, as.numeric))
lm.fit <- lm(log_area ~ .,
data = train.Data)
lm.pred <- predict(lm.fit,
newdata = test.Data
)
lm.fit
predict.lm
lm.pred <- predict(lm.fit,
test.Data)
levels(train.Data$month)
levels(test.Data$month)
lm.pred <- predict(lm.fit,
train.Data)
lm.pred <- predict(lm.fit,
test.Data)
test.Data$month
length(test.Data$month == "nov")
length(test.Data$month == 10)
test.Data$month == 10
test.Data$month == "nov"
train.Data$month == "nov"
sum(as.numeric(Data$month == "nov")
)
test.Data[test.Data$month == "nov", ]
test.Data[test.Data$month != "nov", ]
lm.fit <- lm(log_area ~ .,
data = train.Data)
lm.pred <- predict(lm.fit,
test.Data[test.Data$month != "nov", ])
lm.mse = mean((lm.pred - test.Data$log_area[test.Data$month != "nov"])^2)
lm.mse
summary(Data$log_area)
sd(Data$log_area)
cor(College)
cor(sapply(College, as.numeric))
str(cor(sapply(College, as.numeric)))
attr(cor(sapply(College, as.numeric))[cor(sapply(College, as.numeric))>0.7], "dimnames")
cor(sapply(College, as.numeric))[cor(sapply(College, as.numeric))>0.7]
str(cor(sapply(College, as.numeric))[cor(sapply(College, as.numeric))>0.7])
?reshape
c(cor(sapply(College, as.numeric)))
str(c(cor(sapply(College, as.numeric))))
array(cor(sapply(College, as.numeric)))
str(array(cor(sapply(College, as.numeric))))
install.packages("gdata")
library(gdata)
str(unmatrix(cor(sapply(College, as.numeric))))
attr(unmatrix(cor(sapply(College, as.numeric)))[unmatrix(cor(sapply(College, as.numeric)))>0.7], "dimnames")
attr(unmatrix(cor(sapply(College, as.numeric)))[unmatrix(cor(sapply(College, as.numeric)))>0.7], "dimnames")
unmatrix(cor(sapply(College, as.numeric)))[unmatrix(cor(sapply(College, as.numeric)))>0.7]
unmatrix(cor(sapply(College, as.numeric)))[unmatrix(cor(sapply(College, as.numeric)))>0.7, "names"]
attr(unmatrix(cor(sapply(College, as.numeric)))[unmatrix(cor(sapply(College, as.numeric)))>0.7], "names")
College.cor <- sapply(College, as.numeric)
College.num <- sapply(College, as.numeric)
College.cor <- cor(College.num[, 2], College.num[, -2])
College.cor
str(College.cor)
unmatrix(College.cor)[unmatrix(College.cor)>0.7]
unmatrix(College.cor)[unmatrix(College.cor)>0.6]
unmatrix(College.cor)[unmatrix(College.cor)>0.5]
College.cor[1, College.cor[1, ]>0.5]
College.cor[1, College.cor[1, ]>0.3]
College.cor[1, College.cor[1, ]>0.5]
set.seed(1)
pcr.fit <- pcr(log_area ~ .,
data = train.Data,
scale = FALSE,
validation = "CV",
segments = 5)
M.ind <- which.min(RMSEP(pcr.fit)$val[1, 1, ])
best.pcr.fit <- attr(RMSEP(pcr.fit)$val, "dimnames")$model[M.ind]
M <- as.numeric(gsub("([0-9]+).*$", "\\1", best.pcr.fit))
pcr.pred <- predict(pcr.fit,
model.matrix(log_area ~ ., test.Data)[, -1],
ncomp = M)
pcr.mse = mean((pcr.pred - test.Data$log_area)^2)
M.ind
set.seed(1)
plsr.fit <- plsr(log_area ~ .,
data = train.Data[, c(-3, -4)],
scale = TRUE,
validation = "CV",
segments = 5)
M.ind <- which.min(RMSEP(plsr.fit)$val[1, 1, ])
best.plsr.fit <- attr(RMSEP(plsr.fit)$val, "dimnames")$model[M.ind]
M <- as.numeric(gsub("([0-9]+).*$", "\\1", best.plsr.fit))
plsr.pred <- predict(plsr.fit,
model.matrix(log_area ~ ., test.Data[, c(-3, -4)])[,-1],
ncomp = M))
plsr.mse = mean((plsr.pred - test.Data$log_area)^2)
set.seed(1)
plsr.fit <- plsr(log_area ~ .,
data = train.Data[, c(-3, -4)],
scale = TRUE,
validation = "CV",
segments = 5)
M.ind <- which.min(RMSEP(plsr.fit)$val[1, 1, ])
best.plsr.fit <- attr(RMSEP(plsr.fit)$val, "dimnames")$model[M.ind]
M <- as.numeric(gsub("([0-9]+).*$", "\\1", best.plsr.fit))
plsr.pred <- predict(plsr.fit,
model.matrix(log_area ~ ., test.Data[, c(-3, -4)])[,-1],
ncomp = M)
plsr.mse = mean((plsr.pred - test.Data$log_area)^2)
M.ind
set.seed(1)
lasso.cv.out <- cv.glmnet(x = model.matrix(log_area ~ ., train.Data)[,-1],
y = train.Data$log_area,
alpha = 1,
nfolds = 5)
lasso.bestlam <- lasso.cv.out$lambda.min
lasso.mod <- glmnet(x = model.matrix(log_area ~ ., train.Data)[,-1],
y = train.Data$log_area,
alpha = 1,
lambda = lasso.bestlam)
lasso.pred <- predict(lasso.mod,
s = lasso.bestlam,
newx = model.matrix(log_area ~ ., test.Data)[,-1])
lasso.pred <- predict(lasso.mod,
s = lasso.bestlam,
newx = model.matrix(log_area ~ ., train.Data)[,-1])
lasso.mse = mean((lasso.pred - train.Data$log_area)^2)
lasso.mse
mean((lasso.pred - test.Data$log_area)^2)
str(pcr.fit)
pcr.fit$validation$adj
summary(pcr.fit)
RMSEP(pcr.fit)
str(RMSEP(pcr.fit))
lasso.fi
lasso.fit
lasso.mod
str(lasso.cv.out)
summary(lasso.cv.out)
lasso.cv.out$cvm
lasso.bestlam
lasso.cv.out$lambda
min(lasso.cv.out$cvm)
MSEP(pcr.fit)
RMSEP(pcr.fit)
str(MSEP(pcr.fit))
set.seed(1)
folds=sample(1:k,
nrow(train.Data),
replace = TRUE)
cv.errors <- matrix(NA,
k,
N,
dimnames=list(NULL, paste(1:13)))
for(j in 1:k){
best.fit <- regsubsets(log_area ~ .,
data=train.Data[folds != j, ],
nvmax=N)
for(i in 1:13){
pred <- predict(best.fit,
train.Data[folds == j, ],
id = i)
cv.errors[j,i] <- mean((train.Data$log_area[folds == j] - pred)^2)
}
}
mean.cv.errors <- apply(cv.errors, 2, mean)
best.ind <- which.min(mean.cv.errors)
reg.best <- regsubsets(log_area ~ . ,
data=train.Data,
nvmax=N)
best.lm <- lm(as.formula(paste("log_area ~ ",
paste(attr(coef(reg.best, best.ind),
"names")[-1],
collapse = " + "))),
data = train.Data)
best.pred <- predict(best.lm,
newdata = test.Data[test.Data$month != "nov", ])
lm.mse = mean((best.pred - test.Data$log_area[test.Data$month != "nov"])^2)
set.seed(1)
folds=sample(1:k,
nrow(train.Data),
replace = TRUE)
cv.errors <- matrix(NA,
k,
N,
dimnames=list(NULL, paste(1:N)))
for(j in 1:k){
best.fit <- regsubsets(log_area ~ .,
data=train.Data[folds != j, ],
nvmax=N)
for(i in 1:13){
pred <- predict(best.fit,
train.Data[folds == j, ],
id = i)
cv.errors[j,i] <- mean((train.Data$log_area[folds == j] - pred)^2)
}
}
mean.cv.errors <- apply(cv.errors, 2, mean)
best.ind <- which.min(mean.cv.errors)
reg.best <- regsubsets(log_area ~ . ,
data=train.Data,
nvmax=N)
best.lm <- lm(as.formula(paste("log_area ~ ",
paste(attr(coef(reg.best, best.ind),
"names")[-1],
collapse = " + "))),
data = train.Data)
best.pred <- predict(best.lm,
newdata = test.Data[test.Data$month != "nov", ])
lm.mse = mean((best.pred - test.Data$log_area[test.Data$month != "nov"])^2)
sd(Data$log_area)
?sd
